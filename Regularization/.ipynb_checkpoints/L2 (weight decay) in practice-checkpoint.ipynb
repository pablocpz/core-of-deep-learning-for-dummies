{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d721d786-758b-4f01-9b57-5a5d7033c2d4",
   "metadata": {},
   "source": [
    "## L2 Regularization (Weight Decay) in practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52978332-2e0c-4663-8a61-f55f61788729",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%config InlineBackend.figure_formats = ['svg']\n",
    "%matplotlib inline\n",
    "plt.style.use(\"dark_background\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3aee5f86-5ae1-4d0f-accb-eeb03a302946",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "df_iris = sns.load_dataset(\"iris\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "679855df-0101-47d1-87fb-18a1d44fa163",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "#transformamos las etiquetas (y) de los datos a ser números desde 0 a n_clases-1\n",
    "label_enc = LabelEncoder()\n",
    "\n",
    "labels = label_enc.fit_transform(df_iris.species)\n",
    "\n",
    "X = torch.tensor(df_iris.iloc[:,0:4].values).float() #matriz de características\n",
    "y = torch.tensor(labels).long() #vector de las etiquetas transformadas a números (tipo de dato long() -> entero) #podiamos tambien haber hecho df.iris[df.iris.species==\"setosa\"] == 1 y así"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcf8fa72-e39d-40b4-8c26-95c2ca32f57d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d4082c9-4ebf-47e4-9165-333fcacdac30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = TensorDataset(X_train, y_train)\n",
    "test_data = TensorDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f79b2a54-81e3-4958-b207-14b58dc200f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 16 #suelen ser potencias de 2\n",
    "\n",
    "train_loader = DataLoader(train_data,\n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(test_data,\n",
    "                        batch_size=test_data.tensors[0].shape[0])\n",
    "#train_data.tensors[0] accede a las características X\n",
    "#para predicciones del modelo, los lotes son individuales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1caae6b-2710-4e69-a1dd-82b41a7d6c1a",
   "metadata": {},
   "source": [
    "<img src=\"l2 weight decay details.jpg\" alt=\"info\" width=700>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0afe21c0-eb8f-4639-9cc4-1eaa633ab14a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.inp = nn.Linear(4, 64),\n",
    "        self.hid = nn.Linear(64, 64),\n",
    "        self.out = nn.Linear(64, 3)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.relu(self.inp(x))\n",
    "        x = F.relu(self.hid(x))\n",
    "        x = self.out(x)\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479b1f6b-c0af-460b-aa0f-552d4af07305",
   "metadata": {},
   "source": [
    "## Ajustaremos el tamaño del coeficiente de penalización $\\large\\lambda$ a través del parámetro `l2_lambda`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "babe4207-4a9e-4bc1-bb45-94478db2b039",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_model(l2_lambda):\n",
    "    \n",
    "    model = Model()\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    optim = torch.optim.SGD(params=model.parameters(),\n",
    "                       lr=0.005,\n",
    "                       weight_decay=l2_lambda) #aquí se ubicará el parámetro\n",
    "    \n",
    "    return model, loss_func, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c03ca23-1aa0-48b9-91e7-e7ed075062df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(model, loss_func, optim):\n",
    "    \n",
    "    train_accs = []\n",
    "    test_accs = []\n",
    "    losses = []\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        \n",
    "        batch_accs = []\n",
    "        batch_loss = []\n",
    "        \n",
    "        for (X_batch, y_batch) in train_loader:\n",
    "            \n",
    "            y_hat = model(X_batch)\n",
    "            \n",
    "            loss = loss_func(y_hat, y_batch)\n",
    "            \n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            \n",
    "\n",
    "            batch_accs.append(100*torch.mean((torch.argmax(y_hat, axis=1) == y_batch).float()).item())\n",
    "            batch_loss.append(loss.item())\n",
    "        \n",
    "        #al final de cada epoch\n",
    "        train_accs.append(np.mean(batch_accs))\n",
    "        losses.append(np.mean(batch_loss))\n",
    "        \n",
    "        #test\n",
    "        X_test, y_test = next(iter(test_loader)) #extraemos los datos del generador\n",
    "        preds = model(X_test)\n",
    "        test_accs.append(100*torch.mean((torch.argmax(preds, axis=1) == y_test).float()).item())\n",
    "        \n",
    "    \n",
    "    return train_accs, test_accs, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ddb691-b6a4-4b72-bbe6-02ecb4f7849a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6e9812-59cb-453c-81ef-a52b2bbaf20c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba979a48-0534-46ca-9488-81a749f6f40a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23de8d2a-88bd-4131-8d5d-ec382956748b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da608d3-a307-4729-b162-1eb631ded5b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ea1034-c8ce-45f4-ad7f-719915289983",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_workflow]",
   "language": "python",
   "name": "conda-env-pytorch_workflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
